{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#注意事项:\n",
    "#当运行本Notebook的程序后，如果要关闭Notebook，请选择菜单: File > Close and Halt 才能确实停止当前正在运行的程序，并且释放资源\n",
"#如果没有使用以上方法，只关闭此分页，程序仍在运行，未释放资源，当您打开并运行其他的Notebook，可能会发生错误"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20\tSpark ML Pipeline 二元分类机器学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'spark://master:7077'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20.1\t数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global Path    \n",
    "if sc.master[0:5]==\"local\" :\n",
    "   Path=\"file:/home/hduser/pythonsparkexample/PythonProject/\"\n",
    "else:   \n",
    "   Path=\"hdfs://master:9000/user/hduser/\"\n",
    "#如果要在cluster模式运行(hadoop yarn 或Spark Stand alone)，请按照书上的说明，先把文件上传到HDFS目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7395\n"
     ]
    }
   ],
   "source": [
    "row_df = sqlContext.read.format(\"csv\") \\\n",
    "     .option(\"header\", \"true\") \\\n",
    "     .option(\"delimiter\", \"\\t\") \\\n",
    "     .load(Path+\"data/train.tsv\")\n",
    "print row_df.count()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- url: string (nullable = true)\n",
      " |-- urlid: string (nullable = true)\n",
      " |-- boilerplate: string (nullable = true)\n",
      " |-- alchemy_category: string (nullable = true)\n",
      " |-- alchemy_category_score: string (nullable = true)\n",
      " |-- avglinksize: string (nullable = true)\n",
      " |-- commonlinkratio_1: string (nullable = true)\n",
      " |-- commonlinkratio_2: string (nullable = true)\n",
      " |-- commonlinkratio_3: string (nullable = true)\n",
      " |-- commonlinkratio_4: string (nullable = true)\n",
      " |-- compression_ratio: string (nullable = true)\n",
      " |-- embed_ratio: string (nullable = true)\n",
      " |-- framebased: string (nullable = true)\n",
      " |-- frameTagRatio: string (nullable = true)\n",
      " |-- hasDomainLink: string (nullable = true)\n",
      " |-- html_ratio: string (nullable = true)\n",
      " |-- image_ratio: string (nullable = true)\n",
      " |-- is_news: string (nullable = true)\n",
      " |-- lengthyLinkDomain: string (nullable = true)\n",
      " |-- linkwordscore: string (nullable = true)\n",
      " |-- news_front_page: string (nullable = true)\n",
      " |-- non_markup_alphanum_characters: string (nullable = true)\n",
      " |-- numberOfLinks: string (nullable = true)\n",
      " |-- numwords_in_url: string (nullable = true)\n",
      " |-- parametrizedLinkRatio: string (nullable = true)\n",
      " |-- spelling_errors_ratio: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+----------------------+-------+-----+\n",
      "|                 url|  alchemy_category|alchemy_category_score|is_news|label|\n",
      "+--------------------+------------------+----------------------+-------+-----+\n",
      "|http://www.bloomb...|          business|              0.789131|      1|    0|\n",
      "|http://www.popsci...|        recreation|              0.574147|      1|    1|\n",
      "|http://www.menshe...|            health|              0.996526|      1|    1|\n",
      "|http://www.dumbli...|            health|              0.801248|      1|    1|\n",
      "|http://bleacherre...|            sports|              0.719157|      1|    0|\n",
      "|http://www.conven...|                 ?|                     ?|      ?|    0|\n",
      "|http://gofashionl...|arts_entertainment|               0.22111|      1|    1|\n",
      "|http://www.inside...|                 ?|                     ?|      ?|    0|\n",
      "|http://www.valetm...|                 ?|                     ?|      1|    1|\n",
      "|http://www.howswe...|                 ?|                     ?|      ?|    1|\n",
      "+--------------------+------------------+----------------------+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row_df.select('url','alchemy_category','alchemy_category_score','is_news','label').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "def replace_question(x):\n",
    "    return (\"0\" if x==\"?\" else x)\n",
    "replace_question= udf(replace_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col  \n",
    "import pyspark.sql.types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df= row_df.select(\n",
    "               ['url','alchemy_category' ]+\n",
    "               [replace_question(col(column)).cast(\"double\").alias(column)  \n",
    "                for column in row_df.columns[4:] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- url: string (nullable = true)\n",
      " |-- alchemy_category: string (nullable = true)\n",
      " |-- alchemy_category_score: double (nullable = true)\n",
      " |-- avglinksize: double (nullable = true)\n",
      " |-- commonlinkratio_1: double (nullable = true)\n",
      " |-- commonlinkratio_2: double (nullable = true)\n",
      " |-- commonlinkratio_3: double (nullable = true)\n",
      " |-- commonlinkratio_4: double (nullable = true)\n",
      " |-- compression_ratio: double (nullable = true)\n",
      " |-- embed_ratio: double (nullable = true)\n",
      " |-- framebased: double (nullable = true)\n",
      " |-- frameTagRatio: double (nullable = true)\n",
      " |-- hasDomainLink: double (nullable = true)\n",
      " |-- html_ratio: double (nullable = true)\n",
      " |-- image_ratio: double (nullable = true)\n",
      " |-- is_news: double (nullable = true)\n",
      " |-- lengthyLinkDomain: double (nullable = true)\n",
      " |-- linkwordscore: double (nullable = true)\n",
      " |-- news_front_page: double (nullable = true)\n",
      " |-- non_markup_alphanum_characters: double (nullable = true)\n",
      " |-- numberOfLinks: double (nullable = true)\n",
      " |-- numwords_in_url: double (nullable = true)\n",
      " |-- parametrizedLinkRatio: double (nullable = true)\n",
      " |-- spelling_errors_ratio: double (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+----------------------+-------+-----+\n",
      "|                 url|  alchemy_category|alchemy_category_score|is_news|label|\n",
      "+--------------------+------------------+----------------------+-------+-----+\n",
      "|http://www.bloomb...|          business|              0.789131|    1.0|  0.0|\n",
      "|http://www.popsci...|        recreation|              0.574147|    1.0|  1.0|\n",
      "|http://www.menshe...|            health|              0.996526|    1.0|  1.0|\n",
      "|http://www.dumbli...|            health|              0.801248|    1.0|  1.0|\n",
      "|http://bleacherre...|            sports|              0.719157|    1.0|  0.0|\n",
      "|http://www.conven...|                 ?|                   0.0|    0.0|  0.0|\n",
      "|http://gofashionl...|arts_entertainment|               0.22111|    1.0|  1.0|\n",
      "|http://www.inside...|                 ?|                   0.0|    0.0|  0.0|\n",
      "|http://www.valetm...|                 ?|                   0.0|    1.0|  1.0|\n",
      "|http://www.howswe...|                 ?|                   0.0|    0.0|  1.0|\n",
      "+--------------------+------------------+----------------------+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('url','alchemy_category','alchemy_category_score','is_news','label').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[url: string, alchemy_category: string, alchemy_category_score: double, avglinksize: double, commonlinkratio_1: double, commonlinkratio_2: double, commonlinkratio_3: double, commonlinkratio_4: double, compression_ratio: double, embed_ratio: double, framebased: double, frameTagRatio: double, hasDomainLink: double, html_ratio: double, image_ratio: double, is_news: double, lengthyLinkDomain: double, linkwordscore: double, news_front_page: double, non_markup_alphanum_characters: double, numberOfLinks: double, numwords_in_url: double, parametrizedLinkRatio: double, spelling_errors_ratio: double, label: double]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = df.randomSplit([0.7, 0.3])\n",
    "train_df.cache()\n",
    "test_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20.2\t介绍数据处理的pipeline管线的组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import  StringIndexer, OneHotEncoder,VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import  StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categoryIndexer = StringIndexer(\n",
    "                                   inputCol='alchemy_category', \n",
    "                                   outputCol=\"alchemy_category_Index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categoryTransformer=categoryIndexer.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:?\n",
      "1:recreation\n",
      "2:arts_entertainment\n",
      "3:business\n",
      "4:health\n",
      "5:sports\n",
      "6:culture_politics\n",
      "7:computer_internet\n",
      "8:science_technology\n",
      "9:gaming\n",
      "10:religion\n",
      "11:law_crime\n",
      "12:unknown\n",
      "13:weather\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(categoryTransformer.labels)):\n",
    "    print str(i)+':'+categoryTransformer.labels[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1=categoryTransformer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['url', 'alchemy_category', 'alchemy_category_score', 'avglinksize', 'commonlinkratio_1', 'commonlinkratio_2', 'commonlinkratio_3', 'commonlinkratio_4', 'compression_ratio', 'embed_ratio', 'framebased', 'frameTagRatio', 'hasDomainLink', 'html_ratio', 'image_ratio', 'is_news', 'lengthyLinkDomain', 'linkwordscore', 'news_front_page', 'non_markup_alphanum_characters', 'numberOfLinks', 'numwords_in_url', 'parametrizedLinkRatio', 'spelling_errors_ratio', 'label', 'alchemy_category_Index']\n"
     ]
    }
   ],
   "source": [
    "print df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------------+\n",
      "|  alchemy_category|alchemy_category_Index|\n",
      "+------------------+----------------------+\n",
      "|          business|                   3.0|\n",
      "|        recreation|                   1.0|\n",
      "|            health|                   4.0|\n",
      "|            health|                   4.0|\n",
      "|            sports|                   5.0|\n",
      "|                 ?|                   0.0|\n",
      "|arts_entertainment|                   2.0|\n",
      "|                 ?|                   0.0|\n",
      "|                 ?|                   0.0|\n",
      "|                 ?|                   0.0|\n",
      "+------------------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(\"alchemy_category\",\"alchemy_category_Index\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import  OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(dropLast=False,\n",
    "                            inputCol='alchemy_category_Index', \n",
    "                            outputCol=\"alchemy_category_IndexVec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['url', 'alchemy_category', 'alchemy_category_score', 'avglinksize', 'commonlinkratio_1', 'commonlinkratio_2', 'commonlinkratio_3', 'commonlinkratio_4', 'compression_ratio', 'embed_ratio', 'framebased', 'frameTagRatio', 'hasDomainLink', 'html_ratio', 'image_ratio', 'is_news', 'lengthyLinkDomain', 'linkwordscore', 'news_front_page', 'non_markup_alphanum_characters', 'numberOfLinks', 'numwords_in_url', 'parametrizedLinkRatio', 'spelling_errors_ratio', 'label', 'alchemy_category_Index', 'alchemy_category_IndexVec']\n"
     ]
    }
   ],
   "source": [
    "df2=encoder.transform(df1)\n",
    "print df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------------+-------------------------+\n",
      "|  alchemy_category|alchemy_category_Index|alchemy_category_IndexVec|\n",
      "+------------------+----------------------+-------------------------+\n",
      "|          business|                   3.0|           (14,[3],[1.0])|\n",
      "|        recreation|                   1.0|           (14,[1],[1.0])|\n",
      "|            health|                   4.0|           (14,[4],[1.0])|\n",
      "|            health|                   4.0|           (14,[4],[1.0])|\n",
      "|            sports|                   5.0|           (14,[5],[1.0])|\n",
      "|                 ?|                   0.0|           (14,[0],[1.0])|\n",
      "|arts_entertainment|                   2.0|           (14,[2],[1.0])|\n",
      "|                 ?|                   0.0|           (14,[0],[1.0])|\n",
      "|                 ?|                   0.0|           (14,[0],[1.0])|\n",
      "|                 ?|                   0.0|           (14,[0],[1.0])|\n",
      "+------------------+----------------------+-------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"alchemy_category\",\"alchemy_category_Index\",\n",
    "                    \"alchemy_category_IndexVec\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import  VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alchemy_category_IndexVec', 'alchemy_category_score', 'avglinksize', 'commonlinkratio_1', 'commonlinkratio_2', 'commonlinkratio_3', 'commonlinkratio_4', 'compression_ratio', 'embed_ratio', 'framebased', 'frameTagRatio', 'hasDomainLink', 'html_ratio', 'image_ratio', 'is_news', 'lengthyLinkDomain', 'linkwordscore', 'news_front_page', 'non_markup_alphanum_characters', 'numberOfLinks', 'numwords_in_url', 'parametrizedLinkRatio', 'spelling_errors_ratio']\n"
     ]
    }
   ],
   "source": [
    "assemblerInputs =['alchemy_category_IndexVec']  +  row_df.columns[4:-1]\n",
    "print assemblerInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "                            inputCols=assemblerInputs,  \n",
    "                            outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3=assembler.transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['url', 'alchemy_category', 'alchemy_category_score', 'avglinksize', 'commonlinkratio_1', 'commonlinkratio_2', 'commonlinkratio_3', 'commonlinkratio_4', 'compression_ratio', 'embed_ratio', 'framebased', 'frameTagRatio', 'hasDomainLink', 'html_ratio', 'image_ratio', 'is_news', 'lengthyLinkDomain', 'linkwordscore', 'news_front_page', 'non_markup_alphanum_characters', 'numberOfLinks', 'numwords_in_url', 'parametrizedLinkRatio', 'spelling_errors_ratio', 'label', 'alchemy_category_Index', 'alchemy_category_IndexVec', 'features']\n"
     ]
    }
   ],
   "source": [
    "print df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|(36,[3,14,15,16,1...|\n",
      "|(36,[1,14,15,16,1...|\n",
      "|(36,[4,14,15,16,1...|\n",
      "|(36,[4,14,15,16,1...|\n",
      "|(36,[5,14,15,16,1...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.select('features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=SparseVector(36, {3: 1.0, 14: 0.7891, 15: 2.0556, 16: 0.6765, 17: 0.2059, 18: 0.0471, 19: 0.0235, 20: 0.4438, 23: 0.0908, 25: 0.2458, 26: 0.0039, 27: 1.0, 28: 1.0, 29: 24.0, 31: 5424.0, 32: 170.0, 33: 8.0, 34: 0.1529, 35: 0.0791}))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.select('features').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol=\"label\",  featuresCol=\"features\",\n",
    "                                              impurity=\"gini\",maxDepth=10, maxBins=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_47bfbe3b2a9b0806f2f4) of depth 10 with 723 nodes\n"
     ]
    }
   ],
   "source": [
    "dt_model=dt.fit(df3)\n",
    "print dt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4=dt_model.transform(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20.3\t建立数据处理的pipeline管线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import  StringIndexer, OneHotEncoder,VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCol='alchemy_category', \n",
    "                                                outputCol=\"alchemy_category_Index\")\n",
    "encoder = OneHotEncoder(dropLast=False,\n",
    "                                            inputCol='alchemy_category_Index',\n",
    "                                            outputCol=\"alchemy_category_IndexVec\")\n",
    "assemblerInputs =['alchemy_category_IndexVec']  + row_df.columns[4:-1] \n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\",impurity=\"gini\",\n",
    "                                                   maxDepth=10, maxBins=14)\n",
    "pipeline = Pipeline(stages=[stringIndexer,encoder ,assembler,dt ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_4b34ad72ca393b323196,\n",
       " OneHotEncoder_4dbdbf1b40995af06d47,\n",
       " VectorAssembler_42f0a4cf10ed2b1f2406,\n",
       " DecisionTreeClassifier_4b07b70db603702b8a56]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.getStages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20.4\t使用pipeline进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipelineModel = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4b07b70db603702b8a56) of depth 10 with 477 nodes"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineModel.stages[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4b07b70db603702b8a56) of depth 10 with 477 nodes\n",
      "  If (feature 31 <= 1309.0)\n",
      "   If (feature 23 <= 0.035783366)\n",
      "    If (feature 16 <= 0.757255937)\n",
      "     If (feature 32 <= 50.0)\n",
      "      If (feature 9 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 9 not in {1.0})\n",
      "       If (feature 4 in {1.0})\n",
      "        Predict: 1.0\n",
      "       Else (feature 4 not in {1.0})\n",
      "        If (feature 15 <= 2.76744186)\n",
      "         If (feature 35 <= 0.116883117)\n",
      "          If (feature 35 <= 0.077970297)\n",
      "           If (feature 35 <= 0.064676617)\n",
      "            Predict: 1.0\n",
      "           Else (feature 35 > 0.064676617)\n",
      "            Predict: 0.0\n",
      "          Else (feature 35 > 0.077970297)\n",
      "           If (feature 33 <= 0.0)\n",
      "            Predict: 0.0\n",
      "           Else (feature 33 > 0.0)\n",
      "            Predict: 1.0\n",
      "         Else (feature 35 > 0.116883117)\n",
      "          If (feature 29 <= 25.0)\n",
      "           If (feature 15 <= 1.540540541)\n",
      "            Predict: 1.0\n",
      "           Else (feature 15 > 1.5\n"
     ]
    }
   ],
   "source": [
    "print pipelineModel.stages[3].toDebugString[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20.5\t使用pipeline 进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted=pipelineModel.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['url',\n",
       " 'alchemy_category',\n",
       " 'alchemy_category_score',\n",
       " 'avglinksize',\n",
       " 'commonlinkratio_1',\n",
       " 'commonlinkratio_2',\n",
       " 'commonlinkratio_3',\n",
       " 'commonlinkratio_4',\n",
       " 'compression_ratio',\n",
       " 'embed_ratio',\n",
       " 'framebased',\n",
       " 'frameTagRatio',\n",
       " 'hasDomainLink',\n",
       " 'html_ratio',\n",
       " 'image_ratio',\n",
       " 'is_news',\n",
       " 'lengthyLinkDomain',\n",
       " 'linkwordscore',\n",
       " 'news_front_page',\n",
       " 'non_markup_alphanum_characters',\n",
       " 'numberOfLinks',\n",
       " 'numwords_in_url',\n",
       " 'parametrizedLinkRatio',\n",
       " 'spelling_errors_ratio',\n",
       " 'label',\n",
       " 'alchemy_category_Index',\n",
       " 'alchemy_category_IndexVec',\n",
       " 'features',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------+--------------------+-----+----------+\n",
      "|                 url|            features|rawprediction|         probability|label|prediction|\n",
      "+--------------------+--------------------+-------------+--------------------+-----+----------+\n",
      "|http://1000awesom...|(36,[0,15,16,17,1...| [96.0,339.0]|[0.22068965517241...|  1.0|       1.0|\n",
      "|http://30aeats.co...|(36,[0,15,16,17,1...|  [12.0,24.0]|[0.33333333333333...|  1.0|       1.0|\n",
      "|http://3kidsandus...|(36,[0,15,16,17,1...| [61.0,151.0]|[0.28773584905660...|  0.0|       1.0|\n",
      "|http://3kidsandus...|(36,[0,15,16,17,1...|  [12.0,24.0]|[0.33333333333333...|  1.0|       1.0|\n",
      "|http://6jokes.com...|(36,[3,14,15,16,1...|   [68.0,8.0]|[0.89473684210526...|  0.0|       0.0|\n",
      "|http://9gg.us/hah...|(36,[12,14,15,20,...|   [20.0,2.0]|[0.90909090909090...|  0.0|       0.0|\n",
      "|http://9gg.us/jus...|(36,[2,14,15,16,2...|   [35.0,0.0]|           [1.0,0.0]|  0.0|       0.0|\n",
      "|http://abeautiful...|(36,[1,14,15,16,1...| [17.0,125.0]|[0.11971830985915...|  1.0|       1.0|\n",
      "|http://acontinuou...|(36,[2,14,15,16,1...| [96.0,339.0]|[0.22068965517241...|  0.0|       1.0|\n",
      "|http://aftenposte...|(36,[0,15,16,17,1...|  [93.0,89.0]|[0.51098901098901...|  0.0|       0.0|\n",
      "+--------------------+--------------------+-------------+--------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted.select('url','features','rawprediction','probability','label','prediction').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(probability=DenseVector([0.2207, 0.7793]), prediction=1.0),\n",
       " Row(probability=DenseVector([0.3333, 0.6667]), prediction=1.0),\n",
       " Row(probability=DenseVector([0.2877, 0.7123]), prediction=1.0),\n",
       " Row(probability=DenseVector([0.3333, 0.6667]), prediction=1.0),\n",
       " Row(probability=DenseVector([0.8947, 0.1053]), prediction=0.0),\n",
       " Row(probability=DenseVector([0.9091, 0.0909]), prediction=0.0),\n",
       " Row(probability=DenseVector([1.0, 0.0]), prediction=0.0),\n",
       " Row(probability=DenseVector([0.1197, 0.8803]), prediction=1.0),\n",
       " Row(probability=DenseVector([0.2207, 0.7793]), prediction=1.0),\n",
       " Row(probability=DenseVector([0.511, 0.489]), prediction=0.0)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.select('probability','prediction') .take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20.6\t评估模型的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(\n",
    "                              rawPredictionCol=\"rawPrediction\",\n",
    "                              labelCol=\"label\",  \n",
    "                              metricName=\"areaUnderROC\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6370924405873424"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions =pipelineModel.transform(test_df)\n",
    "auc= evaluator.evaluate(predictions)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20.7\t使用TrainValidation进行训练评估找出最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder,TrainValidationSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "  .addGrid(dt.impurity, [ \"gini\",\"entropy\"])\\\n",
    "  .addGrid(dt.maxDepth, [ 5,10,15])\\\n",
    "  .addGrid(dt.maxBins, [10, 15,20])\\\n",
    "  .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tvs = TrainValidationSplit(estimator=dt,evaluator=evaluator,\n",
    "                  estimatorParamMaps=paramGrid,trainRatio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tvs_pipeline = Pipeline(stages=[stringIndexer,encoder ,assembler, tvs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tvs_pipelineModel =tvs_pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4956af220acb83b94d62) of depth 15 with 1637 nodes"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel=tvs_pipelineModel.stages[3].bestModel\n",
    "bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4956af220acb83b94d62) of depth 15 with 1637 nodes\n",
      "  If (feature 31 <= 1213.0)\n",
      "   If (feature 23 <= 0.038626609)\n",
      "    If (feature 2 in {1.0})\n",
      "     If (feature 35 <= 0.097633136)\n",
      "      If (feature 25 <= 0.25600839)\n",
      "       Predict: 0.0\n",
      "      Else (feature 25 > 0.25600839)\n",
      "       If (feature 33 <= 3.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 33 > 3.0)\n",
      "        Predict: 0.0\n",
      "     Else (feature 35 > 0.097633136)\n",
      "      If (feature 15 <= 2.28205\n"
     ]
    }
   ],
   "source": [
    "print bestModel.toDebugString[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6571614250977336"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tvs_pipelineModel.transform(test_df)\n",
    "auc= evaluator.evaluate(predictions)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20.8\t使用crossValidation进行训练评估找出最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=dt, evaluator=evaluator, \n",
    "                    estimatorParamMaps=paramGrid, numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_pipeline = Pipeline(stages=[stringIndexer,encoder ,assembler, cv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_pipelineModel = cv_pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4956af220acb83b94d62) of depth 15 with 1657 nodes"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel=cv_pipelineModel.stages[3].bestModel\n",
    "bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4956af220acb83b94d62) of depth 15 with 1657 nodes\n",
      "  If (feature 31 <= 1213.0)\n",
      "   If (feature 23 <= 0.034250421)\n",
      "    If (feature 16 <= 0.763157895)\n",
      "     If (feature 20 <= 0.46797153)\n",
      "      If (feature 26 <= 0.923076923)\n",
      "       If (feature 18 <= 0.048034934)\n",
      "        Predict: 0.0\n",
      "       Else (feature 18 > 0.048034934)\n",
      "        If (feature 19 <= 0.013100437)\n",
      "         If (feature 27 <= 0.0)\n",
      "          Predict: 1.0\n",
      "         Else (feature 27 > 0\n"
     ]
    }
   ],
   "source": [
    "print bestModel.toDebugString[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6644335142469471"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = cv_pipelineModel.transform(test_df)\n",
    "auc= evaluator.evaluate(predictions)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20.9\t使用RandomForestClassifier分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf =RandomForestClassifier(labelCol=\"label\", \n",
    "                           featuresCol=\"features\",numTrees=10)\n",
    "\n",
    "rfpipeline = Pipeline(stages=[stringIndexer,encoder ,assembler,rf ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7224742063758629"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfpipelineModel = rfpipeline.fit(train_df)\n",
    "rfpredicted=rfpipelineModel.transform(test_df)\n",
    "evaluator.evaluate(rfpredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7566620934481516"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "  .addGrid(rf.impurity, [ \"gini\",\"entropy\"])\\\n",
    "  .addGrid(rf.maxDepth, [ 5,10,15])\\\n",
    "  .addGrid(rf.maxBins, [10, 15,20])\\\n",
    "  .addGrid(rf.numTrees, [10, 20,30])\\\n",
    "  .build()\n",
    "\n",
    "rftvs = TrainValidationSplit(estimator=rf, evaluator=evaluator,\n",
    "                                 estimatorParamMaps=paramGrid, trainRatio=0.8)\n",
    "\n",
    "rftvs_pipeline = Pipeline(stages=[stringIndexer,encoder ,assembler, rftvs])\n",
    "rftvs_pipelineModel =rftvs_pipeline.fit(train_df)\n",
    "rftvspredictions = rftvs_pipelineModel.transform(test_df)\n",
    "auc= evaluator.evaluate(rftvspredictions)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "rfcv = CrossValidator(estimator=rf, evaluator=evaluator, \n",
    "                          estimatorParamMaps=paramGrid, numFolds=3)\n",
    "\n",
    "rfcv_pipeline = Pipeline(stages=[stringIndexer,encoder ,assembler, rfcv])\n",
    "rfcv_pipelineModel = rfcv_pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfcvpredictions = rfcv_pipelineModel.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 网址：  http://1000awesomethings.com/2008/07/07/989-blowing-your-nose-in-the-shower/\n",
      "             ==>预测:1.0 说明:长青网页(evergreen)\n",
      "\n",
      " 网址：  http://30aeats.com/recipes/sun-dried-tomato-kalamata-olive-and-basil-pesto-focaccia/\n",
      "             ==>预测:1.0 说明:长青网页(evergreen)\n",
      "\n",
      " 网址：  http://3kidsandus.com/2011/de-stress-me-dessert-black-forest-brownie-bites/\n",
      "             ==>预测:1.0 说明:长青网页(evergreen)\n",
      "\n",
      " 网址：  http://3kidsandus.com/red-velvet-rice-krispies-treats-hearts-for-valentines-day/\n",
      "             ==>预测:1.0 说明:长青网页(evergreen)\n",
      "\n",
      " 网址：  http://6jokes.com/just-hanging-on-the-wall/\n",
      "             ==>预测:0.0 说明:暂时性网页(ephemeral)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DescDict = {\n",
    "           0: \"暂时性网页(ephemeral)\",\n",
    "           1: \"长青网页(evergreen)\"\n",
    "     }\n",
    "for data in rfcvpredictions .select('url','prediction').take(5):\n",
    "    print \" 网址：  \" +str(data[0])+\"\\n\" +\\\n",
    "                  \"             ==>预测:\"+ str(data[1])+ \\\n",
    "                  \" 说明:\"+DescDict[data[1]] +\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7566620934481524"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc= evaluator.evaluate(rfcvpredictions)\n",
    "auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
